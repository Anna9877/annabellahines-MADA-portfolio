[
  {
    "objectID": "aboutme.html",
    "href": "aboutme.html",
    "title": "About me",
    "section": "",
    "text": "Background Info:\nMy name is Annabella Hines and I am a first year master of public health(MPH) student with a concentration in epidemiology. I graduated in December 2020 from UGA with my undergraduate degree in Biology with an emphasis in marine sciences. I then worked in a dermatopathology lab for approximately two years before returning to UGA to pursue my MPH this past fall. My main interests are in environmental epidemiology and vector borne diseases, but I’m eager to expand my knowledge in new and unexpected areas. My undergraduate research involved surveying Georgia for an invasive tick species and cataloging specimens and environmental data. Last semester I took the introduction to coding in R course and I have some general experience in STATA and SAS. In this course, my goals are to gain knowledge in Git, hone my skills in R, and become more well versed in the tools available for data analysis.\nQuick Picture…\n\n\n\nI’m legally obligated to throw a peace sign in every photo.\n\n\nFun Facts:\n\nI have shown and competed in dog sports for about 10 years!\nI’m obsessed with musicals of all kinds.\nI love to crochet(but I’m not very good at it yet).\n\nCool/Interesting Video:\nI am a big fan of TEDTalks, so when I came across this one I just had to watch it. Sebastian Wernicke analyzed the data available on the popularity of various talks and breaks down how to formulate the ultimate TEDTalk, from topic to color scheme and everything in between. It is about a decade old, but it is a fun watch and I hope you all found it as interesting as I did!"
  },
  {
    "objectID": "coding_exercise.html",
    "href": "coding_exercise.html",
    "title": "R Coding Exercise",
    "section": "",
    "text": "##Loading and checking data\n##Processing Data\n##Initial Plotting\n##Fit\nInfant mortality and life expectancy are significantly correlated at the 0.05 level but population and life expectancy are not."
  },
  {
    "objectID": "coding_exercise.html#lets-create-a-plot-assessing-the-relationship-between-life-expectancy-and-mortality-in-2000-and-look-at-the-impacted-region",
    "href": "coding_exercise.html#lets-create-a-plot-assessing-the-relationship-between-life-expectancy-and-mortality-in-2000-and-look-at-the-impacted-region",
    "title": "R Coding Exercise",
    "section": "Let’s create a plot assessing the relationship between life expectancy and mortality in 2000 and look at the impacted region",
    "text": "Let’s create a plot assessing the relationship between life expectancy and mortality in 2000 and look at the impacted region\n\nggplot(africa2000, aes(x=infant_mortality, y=life_expectancy, color=region)) +geom_point()"
  },
  {
    "objectID": "coding_exercise.html#lets-run-another-regression-prediction-the-average-life-expectancy-in-each-region",
    "href": "coding_exercise.html#lets-run-another-regression-prediction-the-average-life-expectancy-in-each-region",
    "title": "R Coding Exercise",
    "section": "Let’s run another regression prediction the average life expectancy in each region",
    "text": "Let’s run another regression prediction the average life expectancy in each region\n\nfit3 <- lm(life_expectancy ~ region, data = africa2000)\nsummary(fit3)\n\n\nCall:\nlm(formula = life_expectancy ~ region, data = africa2000)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.056  -4.138  -0.500   3.013  17.744 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            53.6563     1.6203  33.115  < 2e-16 ***\nregionMiddle Africa    -0.8562     2.8065  -0.305    0.762    \nregionNorthern Africa  17.4604     3.1026   5.628 1.04e-06 ***\nregionSouthern Africa  -2.1562     3.3206  -0.649    0.519    \nregionWestern Africa    3.1812     2.2915   1.388    0.172    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.481 on 46 degrees of freedom\nMultiple R-squared:  0.4601,    Adjusted R-squared:  0.4131 \nF-statistic:   9.8 on 4 and 46 DF,  p-value: 8.074e-06\n\n\nThis shows that there was a significance difference in life expectancy in the Northern Africa region."
  },
  {
    "objectID": "dataanalysis_exercise.html",
    "href": "dataanalysis_exercise.html",
    "title": "Data Analysis Exercise - Botulism",
    "section": "",
    "text": "Introduction\nThis data is from the CDC website at https://data.cdc.gov/Foodborne-Waterborne-and-Related-Diseases/Botulism/66i6-hisz and has counts of confirmed botulism cases in the United States by state, year, type of botulism toxin, and transmission type. I will be cleaning an working with all 5 variables.\nChange to Factors\nBotType and ToxinType are both classified as characters but would be better represented as factors so I will change them.\nRename Columns\nNext, I think the BotType and ToxinType variables can be renamed to be a little clearer.\nCheck for Missing Data\nRemove NAs\nAll the NA entries appear to be in the state column. There are 2280 observations so I decided to just remove the 34 NA values since they don’t make up a large percentage of the data overall.\nSave as RDS file"
  },
  {
    "objectID": "dataanalysis_exercise.html#abbies-work",
    "href": "dataanalysis_exercise.html#abbies-work",
    "title": "Data Analysis Exercise - Botulism",
    "section": "Abbie’s Work",
    "text": "Abbie’s Work\n1: Load in Data\n\nAKbotulism<-readRDS(\"cleanbotulismdata.RData\") #load() the dataset was shooting errors so I renamed it to read it in\nhead(AKbotulism)\n\n# A tibble: 6 × 5\n  State   Year `Transmission Type` `Toxin Type` Count\n  <chr>  <dbl> <fct>               <fct>        <dbl>\n1 Alaska  1947 Foodborne           Unknown          3\n2 Alaska  1948 Foodborne           Unknown          4\n3 Alaska  1950 Foodborne           E                5\n4 Alaska  1952 Foodborne           E                1\n5 Alaska  1956 Foodborne           E                5\n6 Alaska  1959 Foodborne           E               10\n\n\nI’m interested to see how the toxin types and counts varied by year.\nGrouped By State\n\nlibrary(ggplot2)\nggplot()+\n  geom_line(aes(x=Year, y=Count, group = State), data=AKbotulism, alpha = 0.2)+\n  facet_wrap(.~`Toxin Type`) + \n  theme_bw()\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\nWell that was confusing, let’s try it grouped by Transmission Type.\nGrouped by Transmission Type\n\nggplot()+\n  geom_line(aes(x=Year, y=Count, group = `Transmission Type`), data=AKbotulism, alpha = 0.2)+\n  facet_wrap(.~`Toxin Type`) + \n  theme_bw()\n\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n`geom_line()`: Each group consists of only one observation.\nℹ Do you need to adjust the group aesthetic?\n\n\n\n\n\nWe can see some better patterns here if we squint really hard, but faceting by toxin type allows for too many options to get a good idea of what is happening within the data. Toxins A, B, E, and Unknown seem to be the most prevelant types, so I want to focus in on them\n\nSubset for specific toxins\n\nABE<-AKbotulism%>%\n  filter(`Toxin Type` %in% c(\"A\", \"B\", \"E\", \"Unknown\"))\n\nLet’s try that again:\nGrouped by Transmission Type\n\nggplot()+\n  geom_line(aes(x=Year, y=Count, group = `Transmission Type`), data=ABE, alpha = 0.35)+\n  facet_wrap(.~`Toxin Type`) + \n  theme_bw()\n\n\n\n\nAwesome, now we can start to see the patterns and the ranges better among the data. It seems that Type A is popular and only continues to grow in prevalence. B seems to as well though on a smaller scale. I’m not really sure what’s going on with E, and the number of unknown seems to be decreasing. This may be because these cases are becoming better identified and may account for some of the increase in A and B types (all right around 1975).\nWhile I grouped by Transmission Type to better see the data, that grouping isn’t telling us much at the moments, so let’s see if there’s any patterns within it.\n\nggplot()+\n  geom_point(aes(x=Year, y=Count, color = `Transmission Type`), data=ABE, alpha = 0.35)+\n  facet_wrap(.~`Toxin Type`) + \n  theme_bw()\n\n\n\n\nThis is pretty cool! Most of the new cases for A and B are transmitted by infants with foodborne transmission nearly dying out overnight. The number of unknown types of foodborne transmission also snuffed out around the same time - I wonder if there was new food safety legislation in place that would explain the mass decrease. However, Type E remains mainly foodborne and pretty constant across time. Also with the drastic increase in infant transmission around when foodborne transmission ended I wonder if the classifications for transmission were changed. There’s no instance of “infant” transmission until 1975.\nI don’t know enough about botulism to provide more commentary, but this posed some interesting questions I’ll keep in mind if this topic arises again."
  },
  {
    "objectID": "fluanalysis/code/exploration.html",
    "href": "fluanalysis/code/exploration.html",
    "title": "Flu Analysis Exploration",
    "section": "",
    "text": "#load in necessary packages\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#load-clean-data",
    "href": "fluanalysis/code/exploration.html#load-clean-data",
    "title": "Flu Analysis Exploration",
    "section": "Load Clean Data",
    "text": "Load Clean Data\n\n#load in the cleaned data\nflurevise<- readRDS(file = \"../data/flurevised.rds\")\nglimpse(flurevise)\n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …\n\n\n\n#get a summary of the variables\nflurevise %>% select(BodyTemp, Nausea) %>% summary()\n\n    BodyTemp      Nausea   \n Min.   : 97.20   No :475  \n 1st Qu.: 98.20   Yes:255  \n Median : 98.50            \n Mean   : 98.94            \n 3rd Qu.: 99.30            \n Max.   :103.10"
  },
  {
    "objectID": "fluanalysis/code/exploration.html#data-exploration",
    "href": "fluanalysis/code/exploration.html#data-exploration",
    "title": "Flu Analysis Exploration",
    "section": "Data Exploration",
    "text": "Data Exploration\n\n#create a histogram of the continuous variable BodyTemp \nggplot(flurevise, aes(x=BodyTemp))+geom_histogram()+labs(title=\"Body Temperature Frequencies\", x=\"Body Temperature\", y=\"Count\")+theme_bw()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThe distribution looks fairly normal with most of the temps at normal human ranges from around 98-99 degrees, with nothing looking implausible. There are a few across the 100-103 range which could be considered indicative of a fever.\n\nggplot(flurevise, aes(x=Nausea, y=BodyTemp, fill=Nausea))+geom_boxplot()\n\n\n\n\nHere I was checking how the two outcomes of interest compared to each other in a box plot, they have a pretty even body temperature distribution between those that reported nausea and those that didn’t.\n\nggplot(flurevise, aes(x=SwollenLymphNodes, y=BodyTemp, fill=SwollenLymphNodes))+geom_boxplot()+labs(title = \"Body Temperature Distribution by Lymph Node Status\", x=\"Swollen Lymph Nodes\", y=\"Body Temperature\")\n\n\n\n\nIt seems from a glance that body temperatures were slightly higher in people who reported no swollen lymph nodes.\n\nggplot(flurevise, aes(x=CoughIntensity, y=BodyTemp, fill=CoughIntensity))+geom_boxplot()+labs(x=\"Cough Intensity\", y=\"Body Temperature\", title=\"Body Temperature Distribution by Cough Intensity\")\n\n\n\n\nBody temperature tended to trend higher with more intense coughing.\n\nggplot(flurevise, aes(x=RunnyNose, y=BodyTemp, fill=RunnyNose))+geom_boxplot()+labs(title=\"Body Temperature Distribution by Presence of Runny Nose\", x=\"Runny Nose Status\", y=\"Body Temperature\")"
  },
  {
    "objectID": "fluanalysis/code/fitting.html",
    "href": "fluanalysis/code/fitting.html",
    "title": "Fitting Flu Analysis",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Learn how to get started at https://www.tidymodels.org/start/\n\nlibrary(performance)\n\n\nAttaching package: 'performance'\n\nThe following objects are masked from 'package:yardstick':\n\n    mae, rmse"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#load-data",
    "href": "fluanalysis/code/fitting.html#load-data",
    "title": "Fitting Flu Analysis",
    "section": "Load Data",
    "text": "Load Data\n\n#loading cleaned data\nflufinal<- readRDS(file = \"../data/flurevised.rds\")"
  },
  {
    "objectID": "fluanalysis/code/fitting.html#fitting",
    "href": "fluanalysis/code/fitting.html#fitting",
    "title": "Fitting Flu Analysis",
    "section": "Fitting",
    "text": "Fitting\nFirst I am going to run a linear regression using the main predictor of interest, RunnyNose, against the main continuous outcome of interest, BodyTemp.\n\nlm_mod <- linear_reg() %>% set_engine(\"lm\")\nfitlm1 <- lm_mod %>%\n  fit(BodyTemp ~ RunnyNose, data=flufinal)\n#checking results\nfitlm1\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = BodyTemp ~ RunnyNose, data = data)\n\nCoefficients:\n (Intercept)  RunnyNoseYes  \n     99.1431       -0.2926  \n\ntidy(fitlm1)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic p.value\n  <chr>           <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)    99.1      0.0819   1210.   0      \n2 RunnyNoseYes   -0.293    0.0971     -3.01 0.00268\n\nglance(fitlm1)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1  0.0123  0.0110  1.19    9.08 0.00268     1 -1162. 2329. 2343.   1031.     728\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\n\nFrom this regression it seems that having a runny nose was negatively correlated with body temperature.\nNext we’ll do another linear model with Body Temperature as the outcome but include all the predictors in the data set.\n\nfitlm2 <- lm_mod %>% fit(BodyTemp~., data=flufinal)\n#checking results\ntidy(fitlm2)\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic   p.value\n   <chr>                   <dbl>     <dbl>     <dbl>     <dbl>\n 1 (Intercept)           97.9       0.304   322.     0        \n 2 SwollenLymphNodesYes  -0.165     0.0920   -1.80   0.0727   \n 3 ChestCongestionYes     0.0873    0.0975    0.895  0.371    \n 4 ChillsSweatsYes        0.201     0.127     1.58   0.114    \n 5 NasalCongestionYes    -0.216     0.114    -1.90   0.0584   \n 6 CoughYNYes             0.314     0.241     1.30   0.193    \n 7 SneezeYes             -0.362     0.0983   -3.68   0.000249 \n 8 FatigueYes             0.265     0.161     1.65   0.0996   \n 9 SubjectiveFeverYes     0.437     0.103     4.22   0.0000271\n10 HeadacheYes            0.0115    0.125     0.0913 0.927    \n# … with 28 more rows\n\nglance(fitlm2)\n\n# A tibble: 1 × 12\n  r.squ…¹ adj.r…² sigma stati…³ p.value    df logLik   AIC   BIC devia…⁴ df.re…⁵\n    <dbl>   <dbl> <dbl>   <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>   <dbl>   <int>\n1   0.129  0.0860  1.14    3.02 4.20e-8    34 -1116. 2304. 2469.    909.     695\n# … with 1 more variable: nobs <int>, and abbreviated variable names\n#   ¹​r.squared, ²​adj.r.squared, ³​statistic, ⁴​deviance, ⁵​df.residual\n\n\nNow we will compare th performance of the two models.\n\ncompare_performance(fitlm1, fitlm2)\n\n# Comparison of Model Performance Indices\n\nName   | Model |  AIC (weights) | AICc (weights) |  BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------------------------------------------------------\nfitlm1 |   _lm | 2329.3 (<.001) | 2329.4 (<.001) | 2343.1 (>.999) | 0.012 |     0.011 | 1.188 | 1.190\nfitlm2 |   _lm | 2303.8 (>.999) | 2307.7 (>.999) | 2469.2 (<.001) | 0.129 |     0.086 | 1.116 | 1.144\n\n\nAccording to the R2 value, the second fit with all of the predictors included was better than the first fit with only RunnyNose as a predictor.\nNext we’ll take a look at our other outcome of interest, Nausea. We’ll run a logistic regression with RunnyNose as the predictor.\n\nglm_mod <- logistic_reg() %>% set_engine(\"glm\")\nfluglm1 <- glm_mod %>% fit(Nausea ~ RunnyNose, data=flufinal)\n#checking results\ntidy(fluglm1)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic    p.value\n  <chr>           <dbl>     <dbl>     <dbl>      <dbl>\n1 (Intercept)   -0.658      0.145    -4.53  0.00000589\n2 RunnyNoseYes   0.0502     0.172     0.292 0.770     \n\nglance(fluglm1)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          945.     729  -472.  949.  958.     945.         728   730\n\n\nThen we’ll run another logistic regression with all the predictors of the data and nausea still as the outcome.\n\nfluglm2<- glm_mod %>% fit(Nausea ~., data=flufinal)\n#checking results\ntidy(fluglm2)\n\n# A tibble: 38 × 5\n   term                 estimate std.error statistic p.value\n   <chr>                   <dbl>     <dbl>     <dbl>   <dbl>\n 1 (Intercept)             0.223     7.83     0.0285  0.977 \n 2 SwollenLymphNodesYes   -0.251     0.196   -1.28    0.200 \n 3 ChestCongestionYes      0.276     0.213    1.30    0.195 \n 4 ChillsSweatsYes         0.274     0.288    0.952   0.341 \n 5 NasalCongestionYes      0.426     0.255    1.67    0.0944\n 6 CoughYNYes             -0.140     0.519   -0.271   0.787 \n 7 SneezeYes               0.177     0.210    0.840   0.401 \n 8 FatigueYes              0.229     0.372    0.616   0.538 \n 9 SubjectiveFeverYes      0.278     0.225    1.23    0.218 \n10 HeadacheYes             0.331     0.285    1.16    0.245 \n# … with 28 more rows\n\nglance(fluglm2)\n\n# A tibble: 1 × 8\n  null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs\n          <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>\n1          945.     729  -376.  821.  982.     751.         695   730\n\n\nThen we’ll compare the performance of the two logistic models.\n\ncompare_performance(fluglm1, fluglm2)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# Comparison of Model Performance Indices\n\nName    | Model | AIC (weights) | AICc (weights) | BIC (weights) | Tjur's R2 |  RMSE | Sigma | Log_loss | Score_log | Score_spherical |   PCP\n---------------------------------------------------------------------------------------------------------------------------------------------\nfluglm1 |  _glm | 948.6 (<.001) |  948.6 (<.001) | 957.8 (>.999) | 1.169e-04 | 0.477 | 1.139 |    0.647 |  -107.871 |           0.012 | 0.545\nfluglm2 |  _glm | 821.5 (>.999) |  825.1 (>.999) | 982.2 (<.001) |     0.247 | 0.414 | 1.040 |    0.515 |      -Inf |           0.002 | 0.658\n\n\nThe global model seems to be a better predictor of nausea than just the presence or absence of a runny nose."
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html",
    "href": "fluanalysis/code/machinelearning.html",
    "title": "Machine Learning",
    "section": "",
    "text": "library(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n\n\n✔ broom        1.0.2      ✔ recipes      1.0.4 \n✔ dials        1.1.0      ✔ rsample      1.1.1 \n✔ dplyr        1.0.10     ✔ tibble       3.1.8 \n✔ ggplot2      3.4.0      ✔ tidyr        1.2.1 \n✔ infer        1.0.4      ✔ tune         1.0.1 \n✔ modeldata    1.0.1      ✔ workflows    1.1.2 \n✔ parsnip      1.0.3      ✔ workflowsets 1.0.0 \n✔ purrr        1.0.1      ✔ yardstick    1.1.0 \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n\nlibrary(tidyverse)\n\n── Attaching packages\n───────────────────────────────────────\ntidyverse 1.3.2 ──\n\n\n✔ readr   2.1.3     ✔ forcats 0.5.2\n✔ stringr 1.5.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\n\nlibrary(rpart)\n\nWarning: package 'rpart' was built under R version 4.2.3\n\n\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.2.3\n\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.2.3\n\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-7\n\nlibrary(rpart.plot)\n\nWarning: package 'rpart.plot' was built under R version 4.2.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.2.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#read-in-data",
    "href": "fluanalysis/code/machinelearning.html#read-in-data",
    "title": "Machine Learning",
    "section": "Read in Data",
    "text": "Read in Data\n\n#load in data set\nflu_ml<-readRDS(\"../data/flu_ml.rds\")"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#setup",
    "href": "fluanalysis/code/machinelearning.html#setup",
    "title": "Machine Learning",
    "section": "Setup",
    "text": "Setup\n\n#setting seed for reproducibility\nset.seed(123)\n#Split data with 70% in the training set stratifying on BodyTemp\nflu_split <- initial_split(data=flu_ml, strata = BodyTemp, prop=7/10)\n\n#Create data frames for the two sets:\ntrain_data <- training(flu_split)\ntest_data  <- testing(flu_split)\n\n\n#Cross-validation\nresample_object<-vfold_cv(data=train_data, v=5, repeats=5, strata=BodyTemp)\n#Recipe\nflu_ml_rec <- \n  recipe(BodyTemp ~ ., data = train_data) %>% step_dummy(all_nominal(), -all_outcomes())"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#null-model",
    "href": "fluanalysis/code/machinelearning.html#null-model",
    "title": "Machine Learning",
    "section": "Null Model",
    "text": "Null Model\n\n#Null model recipe\nnull_recipe <- recipe(BodyTemp ~1, train_data) %>% step_dummy(all_nominal(), -all_outcomes())\n#regression model\nln_mod <- linear_reg() %>% set_engine(\"lm\") %>% set_mode(\"regression\")\n#Workflow\nnull_flow <- workflow() %>% add_model(ln_mod) %>% add_recipe(null_recipe)\n#Evaluate\nnull_fit <- null_flow %>% fit(data=train_data) %>% fit_resamples(resamples=resample_object)\n\n! Fold1, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\nnull_metrics<- collect_metrics(null_fit)\nnull_metrics\n\n# A tibble: 2 × 6\n  .metric .estimator   mean     n std_err .config             \n  <chr>   <chr>       <dbl> <int>   <dbl> <chr>               \n1 rmse    standard     1.21    25  0.0177 Preprocessor1_Model1\n2 rsq     standard   NaN        0 NA      Preprocessor1_Model1\n\n#RMSE=1.21"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#fitting-a-tree",
    "href": "fluanalysis/code/machinelearning.html#fitting-a-tree",
    "title": "Machine Learning",
    "section": "Fitting a Tree",
    "text": "Fitting a Tree\n\n#Model Specification\ntune_spec <- \n  decision_tree(\n    cost_complexity = tune(),\n    tree_depth = tune()\n  ) %>% \n  set_engine(\"rpart\") %>% \n  set_mode(\"regression\")\n#Grid specification\ntree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\n#create workflow\ntree_wf <- workflow() %>%\n  add_model(tune_spec) %>%\n  add_recipe(flu_ml_rec)\n#Tuning grid cross validation\ntree_res <- \n  tree_wf %>% \n  tune_grid(\n    resamples = resample_object,\n    grid = tree_grid\n    )\n\n! Fold1, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat1: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat2: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat3: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat4: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold1, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold2, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold3, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold4, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n\n! Fold5, Repeat5: internal: A correlation computation is required, but `estimate` is constant and ha...\n\n#get metrics\ntree_res %>% \n  collect_metrics()\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             <dbl>      <int> <chr>   <chr>         <dbl> <int>    <dbl> <chr>  \n 1    0.0000000001          1 rmse    standard     1.19      25  0.0181  Prepro…\n 2    0.0000000001          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 3    0.0000000178          1 rmse    standard     1.19      25  0.0181  Prepro…\n 4    0.0000000178          1 rsq     standard     0.0361    25  0.00422 Prepro…\n 5    0.00000316            1 rmse    standard     1.19      25  0.0181  Prepro…\n 6    0.00000316            1 rsq     standard     0.0361    25  0.00422 Prepro…\n 7    0.000562              1 rmse    standard     1.19      25  0.0181  Prepro…\n 8    0.000562              1 rsq     standard     0.0361    25  0.00422 Prepro…\n 9    0.1                   1 rmse    standard     1.21      25  0.0177  Prepro…\n10    0.1                   1 rsq     standard   NaN          0 NA       Prepro…\n# … with 40 more rows\n\n\n\n#Plotting\ntree_res %>% autoplot()\n\n\n\n\n\n#Find and show best\ntree_res %>%\n  show_best(n=1)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 1 × 8\n  cost_complexity tree_depth .metric .estimator  mean     n std_err .config     \n            <dbl>      <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \n1    0.0000000001          1 rmse    standard    1.19    25  0.0181 Preprocesso…\n\nbest_tree <- tree_res %>%\n  select_best(n=1)\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n#RMSE = 1.19\n#Finalize workflow\nfinal_wf <- \n  tree_wf %>% \n  finalize_workflow(best_tree)\n#Final fit\nfinal_fit <- \n  final_wf %>%\n  last_fit(flu_split) \n#Final fit metrics\nfinal_fit %>%\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard    1.19     Preprocessor1_Model1\n2 rsq     standard    0.000889 Preprocessor1_Model1\n\n#Plot of final fit\nrpart.plot(extract_fit_parsnip(final_fit)$fit)\n\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE."
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#fitting-a-lasso",
    "href": "fluanalysis/code/machinelearning.html#fitting-a-lasso",
    "title": "Machine Learning",
    "section": "Fitting a LASSO",
    "text": "Fitting a LASSO\n\n#Build the model\nlasso_mod <- \n  linear_reg(penalty = tune(), mixture = 1) %>% \n  set_engine(\"glmnet\")\n#Pull earlier recipe\nflu_ml_rec\n\nRecipe\n\nInputs:\n\n      role #variables\n   outcome          1\n predictor         25\n\nOperations:\n\nDummy variables from all_nominal(), -all_outcomes()\n\n#Create workflow\nlasso_workflow <- \n  workflow() %>% \n  add_model(lasso_mod) %>% \n  add_recipe(flu_ml_rec)\n\n\n#Create tune grid\nlasso_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))\n#Find lowest penalty values\nlasso_grid %>% top_n(-5)\n\nSelecting by penalty\n\n\n# A tibble: 5 × 1\n   penalty\n     <dbl>\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n\n#Highest penalty values\nlasso_grid %>% top_n(5)\n\nSelecting by penalty\n\n\n# A tibble: 5 × 1\n  penalty\n    <dbl>\n1  0.0386\n2  0.0489\n3  0.0621\n4  0.0788\n5  0.1   \n\n\n\n#Train and tune model\nlasso_res <- \n  lasso_workflow %>% \n  tune_grid(resample_object,\n            grid = lasso_grid,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(rmse))\nlasso_res %>% collect_metrics()\n\n# A tibble: 30 × 7\n    penalty .metric .estimator  mean     n std_err .config              \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1 0.0001   rmse    standard    1.18    25  0.0167 Preprocessor1_Model01\n 2 0.000127 rmse    standard    1.18    25  0.0167 Preprocessor1_Model02\n 3 0.000161 rmse    standard    1.18    25  0.0167 Preprocessor1_Model03\n 4 0.000204 rmse    standard    1.18    25  0.0167 Preprocessor1_Model04\n 5 0.000259 rmse    standard    1.18    25  0.0167 Preprocessor1_Model05\n 6 0.000329 rmse    standard    1.18    25  0.0167 Preprocessor1_Model06\n 7 0.000418 rmse    standard    1.18    25  0.0167 Preprocessor1_Model07\n 8 0.000530 rmse    standard    1.18    25  0.0167 Preprocessor1_Model08\n 9 0.000672 rmse    standard    1.18    25  0.0167 Preprocessor1_Model09\n10 0.000853 rmse    standard    1.18    25  0.0167 Preprocessor1_Model10\n# … with 20 more rows\n\n#Plot\nlasso_res %>% autoplot()\n\n\n\n\n\n#Select best performing model\nlasso_res %>% show_best()\n\n# A tibble: 5 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0489 rmse    standard    1.15    25  0.0170 Preprocessor1_Model27\n2  0.0621 rmse    standard    1.15    25  0.0170 Preprocessor1_Model28\n3  0.0386 rmse    standard    1.16    25  0.0170 Preprocessor1_Model26\n4  0.0304 rmse    standard    1.16    25  0.0169 Preprocessor1_Model25\n5  0.0788 rmse    standard    1.16    25  0.0172 Preprocessor1_Model29\n\nbest_lasso<-lasso_res %>% select_best(method=\"rmse\")\nbest_lasso\n\n# A tibble: 1 × 2\n  penalty .config              \n    <dbl> <chr>                \n1  0.0489 Preprocessor1_Model27\n\n#Final workflow\nlasso_final<-lasso_workflow %>% finalize_workflow(best_lasso)\n#Final fit\nlasso_final_fit<-lasso_final %>% fit(train_data)\n#Plot\nx <- extract_fit_engine(lasso_final_fit)\nplot(x, \"lambda\")"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#fitting-a-random-forest",
    "href": "fluanalysis/code/machinelearning.html#fitting-a-random-forest",
    "title": "Machine Learning",
    "section": "Fitting a Random Forest",
    "text": "Fitting a Random Forest\n\n#Build model\ncores <- parallel::detectCores()\ncores\n\n[1] 4\n\nrf_mod <- \n  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% \n  set_engine(\"ranger\", num.threads = cores, importance=\"impurity\") %>% \n  set_mode(\"regression\")\n#Create workflow\nrf_workflow <- \n  workflow() %>% \n  add_model(rf_mod) %>% \n  add_recipe(flu_ml_rec)\n#Parameters for tuning\nextract_parameter_set_dials(rf_mod)\n\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n\n\n\n#Tune grid\nrf_res <- \n  rf_workflow %>% \n  tune_grid(resample_object,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = NULL)\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n#Find and show best\nrf_res %>% show_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     5    27 rmse    standard    1.16    25  0.0168 Preprocessor1_Model18\n2     3    19 rmse    standard    1.16    25  0.0167 Preprocessor1_Model09\n3     8    24 rmse    standard    1.17    25  0.0167 Preprocessor1_Model04\n4    11    36 rmse    standard    1.17    25  0.0168 Preprocessor1_Model13\n5     6    15 rmse    standard    1.17    25  0.0167 Preprocessor1_Model22\n\nrf_best <- rf_res %>% select_best()\n\nWarning: No value of `metric` was given; metric 'rmse' will be used.\n\n#Final workflow\nrf_final_wf<- rf_workflow%>% finalize_workflow(rf_best)\n#Final fit\nrf_final <- rf_final_wf %>% fit(train_data)\nrf_final %>% extract_fit_parsnip() %>% vip(num_features=28)\n\n\n\nfx <- extract_fit_engine(rf_final)\nvip(fx)"
  },
  {
    "objectID": "fluanalysis/code/machinelearning.html#fitting-test-data",
    "href": "fluanalysis/code/machinelearning.html#fitting-test-data",
    "title": "Machine Learning",
    "section": "Fitting Test Data",
    "text": "Fitting Test Data\n\n#I'm deciding to use the lasso fit as the best model because it has the lowest rmse\nfinal_test <- lasso_final %>% last_fit(flu_split)\nfinal_test %>% collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      1.16   Preprocessor1_Model1\n2 rsq     standard      0.0299 Preprocessor1_Model1"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html",
    "href": "fluanalysis/code/modeleval.html",
    "title": "Flu Analysis Model Evaluation",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(skimr)"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#load-data",
    "href": "fluanalysis/code/modeleval.html#load-data",
    "title": "Flu Analysis Model Evaluation",
    "section": "Load Data",
    "text": "Load Data\n\n#load in data set\nfludata<-readRDS(\"../data/flurevised.rds\")"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#data-splitting",
    "href": "fluanalysis/code/modeleval.html#data-splitting",
    "title": "Flu Analysis Model Evaluation",
    "section": "Data Splitting",
    "text": "Data Splitting\n\nset.seed(222)\ndata_split <- initial_split(fludata, prop=3/4)\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#create-recipe",
    "href": "fluanalysis/code/modeleval.html#create-recipe",
    "title": "Flu Analysis Model Evaluation",
    "section": "Create Recipe",
    "text": "Create Recipe\n\n#create recipe\nflu_rec <- \n  recipe(Nausea ~ ., data = train_data) \n#model specification\nlr_mod <- \n  logistic_reg() %>% \n  set_engine(\"glm\")\n#workflow\nflu_wflow <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(flu_rec)\nflu_wflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n\n\n\n#create the fit from the established workflow\nflu_fit <- \n  flu_wflow %>% \n  fit(data = train_data)\n#check prediction to evaluate test data\npredict(flu_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 183 × 1\n   .pred_class\n   <fct>      \n 1 No         \n 2 No         \n 3 No         \n 4 No         \n 5 No         \n 6 Yes        \n 7 Yes        \n 8 No         \n 9 No         \n10 Yes        \n# … with 173 more rows"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#evaluate-performance",
    "href": "fluanalysis/code/modeleval.html#evaluate-performance",
    "title": "Flu Analysis Model Evaluation",
    "section": "Evaluate Performance",
    "text": "Evaluate Performance\n\n#Augment to return probabilities rather than yes or no\nflu_aug <- \n  augment(flu_fit, test_data)\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\n#Use roc_curve to evaluate model\nflu_aug %>% \n  roc_curve(truth = Nausea, .pred_No) %>% \n  autoplot()\n\n\n\n#Use roc_aug to quantify area under roc-curve\nflu_aug %>% \n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.724\n\n\nAccording to the ROC metric, this model is useful as it is over 0.7 at 0.724."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#make-model-with-main-predictor-of-interest",
    "href": "fluanalysis/code/modeleval.html#make-model-with-main-predictor-of-interest",
    "title": "Flu Analysis Model Evaluation",
    "section": "Make model with Main Predictor of Interest",
    "text": "Make model with Main Predictor of Interest\n\n#recipe\nflu_runnynose <- \n  recipe(Nausea ~ RunnyNose, data = train_data) \n#workflow\nflu_wflow_runnynose <- \n  workflow() %>% \n  add_model(lr_mod) %>% \n  add_recipe(flu_runnynose)\n#create fit\nflu_runnynose_fit <- \n  flu_wflow_runnynose %>% \n  fit(data = train_data)"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#evaluate-performance-1",
    "href": "fluanalysis/code/modeleval.html#evaluate-performance-1",
    "title": "Flu Analysis Model Evaluation",
    "section": "Evaluate Performance",
    "text": "Evaluate Performance\n\n#Augment to return probabilities rather than yes or no\nflu_runnynose_aug <- \n  augment(flu_runnynose_fit, test_data)\n#Use roc_curve to evaluate model\nflu_runnynose_aug %>% \n  roc_curve(truth = Nausea, .pred_No) %>% \n  autoplot()\n\n\n\n#Use roc_aug to quantify area under roc-curve\nflu_runnynose_aug %>% \n  roc_auc(truth = Nausea, .pred_No)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.466\n\n\nSince the ROC is estimated to be 0.466, it is not a well performing model according to this metric."
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#model-with-all-predictors",
    "href": "fluanalysis/code/modeleval.html#model-with-all-predictors",
    "title": "Flu Analysis Model Evaluation",
    "section": "Model with all predictors",
    "text": "Model with all predictors\n\n#create the recipe and workflow\nflu_rec_lin <- \n  recipe(BodyTemp ~ ., data = train_data) \n#model specification\nlin_mod <- \n  linear_reg() %>% \n  set_engine(\"lm\")\n#workflow\nflu_wflow_lin <- \n  workflow() %>% \n  add_model(lin_mod) %>% \n  add_recipe(flu_rec_lin)\nflu_wflow_lin\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n#create the fit from the established workflow\nflu_fit_lin <- \n  flu_wflow_lin %>% \n  fit(data = train_data)\n#check prediction to evaluate test data\npredict(flu_fit_lin, test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n\n# A tibble: 183 × 1\n   .pred\n   <dbl>\n 1  99.3\n 2  99.0\n 3  99.7\n 4  98.7\n 5  99.0\n 6  99.5\n 7  99.3\n 8  98.9\n 9  99.6\n10  98.8\n# … with 173 more rows\n\n#Augment to return probabilities \nflu_aug_lin <- \n  augment(flu_fit_lin, test_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n#Calculate mse\n#train model\n\nflu_aug_train_lin <- \n  augment(flu_fit_lin, train_data)\n\nWarning in predict.lm(object = object$fit, newdata = new_data, type =\n\"response\"): prediction from a rank-deficient fit may be misleading\n\n#RSME train\nyardstick::rmse(flu_aug_train_lin, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.11\n\n#RSME test\n\nyardstick::rmse(flu_aug_lin, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.15\n\n\n\n\n\n\n\n\n\nWe see that the training data performed a bit better with our RMSE estimated to be 1.11 versus with the tested data at 1.15, but similar results"
  },
  {
    "objectID": "fluanalysis/code/modeleval.html#model-with-1-predictor",
    "href": "fluanalysis/code/modeleval.html#model-with-1-predictor",
    "title": "Flu Analysis Model Evaluation",
    "section": "Model with 1 predictor",
    "text": "Model with 1 predictor\n\n#create the recipe and workflow\nflu_rec_lin <- \n  recipe(BodyTemp ~ RunnyNose, data = train_data) \n#model specification\nlin_mod <- \n  linear_reg() %>% \n  set_engine(\"lm\")\n#workflow\nflu_wflow_lin <- \n  workflow() %>% \n  add_model(lin_mod) %>% \n  add_recipe(flu_rec_lin)\nflu_wflow_lin\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n\n#create the fit from the established workflow\nflu_fit_lin <- \n  flu_wflow_lin %>% \n  fit(data = train_data)\n#check prediction to evaluate test data\npredict(flu_fit_lin, test_data)\n\n# A tibble: 183 × 1\n   .pred\n   <dbl>\n 1  99.1\n 2  98.9\n 3  98.9\n 4  98.9\n 5  99.1\n 6  99.1\n 7  98.9\n 8  99.1\n 9  99.1\n10  99.1\n# … with 173 more rows\n\n#Augment to return probabilities \nflu_aug_lin <- \n  augment(flu_fit_lin, test_data)\n\n#Calculate mse\n#train model\n\nflu_aug_train_lin <- \n  augment(flu_fit_lin, train_data)\n#RSME train\nyardstick::rmse(flu_aug_train_lin, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.21\n\n#RSME test\n\nyardstick::rmse(flu_aug_lin, BodyTemp, .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard        1.13\n\n\n\n\n\n\n\n\n\nWe see that the training data performed a bit better with our RMSE estimated to be 1.21 versus with the tested data at 1.13, but similar results"
  },
  {
    "objectID": "fluanalysis/code/preprocessing.html",
    "href": "fluanalysis/code/preprocessing.html",
    "title": "Preprocessing for Machine Learning",
    "section": "",
    "text": "#load packages\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.2     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.0.1     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages"
  },
  {
    "objectID": "fluanalysis/code/preprocessing.html#load-in-data",
    "href": "fluanalysis/code/preprocessing.html#load-in-data",
    "title": "Preprocessing for Machine Learning",
    "section": "Load in Data",
    "text": "Load in Data\n\n#load in data set\nfludata<-readRDS(\"../data/flurevised.rds\")"
  },
  {
    "objectID": "fluanalysis/code/preprocessing.html#edit-data",
    "href": "fluanalysis/code/preprocessing.html#edit-data",
    "title": "Preprocessing for Machine Learning",
    "section": "Edit Data",
    "text": "Edit Data\n\n#Removing Variables with yes/no observations that also are represented by a different severity variable\nflu <- fludata %>% select(-c(CoughYN, WeaknessYN, CoughYN2, MyalgiaYN))\n#Unorder the yes/no factor variables\n#Find yes/no variables with less than 50 entries in one category\nsummary(flu)\n\n SwollenLymphNodes ChestCongestion ChillsSweats NasalCongestion Sneeze   \n No :418           No :323         No :130      No :167         No :339  \n Yes:312           Yes:407         Yes:600      Yes:563         Yes:391  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Fatigue   SubjectiveFever Headache      Weakness    CoughIntensity\n No : 64   No :230         No :115   None    : 49   None    : 47   \n Yes:666   Yes:500         Yes:615   Mild    :223   Mild    :154   \n                                     Moderate:338   Moderate:357   \n                                     Severe  :120   Severe  :172   \n                                                                   \n                                                                   \n     Myalgia    RunnyNose AbPain    ChestPain Diarrhea  EyePn     Insomnia \n None    : 79   No :211   No :639   No :497   No :631   No :617   No :315  \n Mild    :213   Yes:519   Yes: 91   Yes:233   Yes: 99   Yes:113   Yes:415  \n Moderate:325                                                              \n Severe  :113                                                              \n                                                                           \n                                                                           \n ItchyEye  Nausea    EarPn     Hearing   Pharyngitis Breathless ToothPn  \n No :551   No :475   No :568   No :700   No :119     No :436    No :565  \n Yes:179   Yes:255   Yes:162   Yes: 30   Yes:611     Yes:294    Yes:165  \n                                                                         \n                                                                         \n                                                                         \n                                                                         \n Vision    Vomit     Wheeze       BodyTemp     \n No :711   No :652   No :510   Min.   : 97.20  \n Yes: 19   Yes: 78   Yes:220   1st Qu.: 98.20  \n                               Median : 98.50  \n                               Mean   : 98.94  \n                               3rd Qu.: 99.30  \n                               Max.   :103.10  \n\n#Remove Hearing and vision\nflu_clean_ml <- flu %>% select(-c(Hearing, Vision))"
  },
  {
    "objectID": "fluanalysis/code/preprocessing.html#save-data",
    "href": "fluanalysis/code/preprocessing.html#save-data",
    "title": "Preprocessing for Machine Learning",
    "section": "Save Data",
    "text": "Save Data\n\n#save to RDS file\nsaveRDS(flu_clean_ml, file=\"../data/flu_ml.rds\")"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html",
    "href": "fluanalysis/code/wrangling.html",
    "title": "Flu Analysis Wrangling",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(here)\n\nhere() starts at C:/Users/annab/Documents/MADA/annabellahines-MADA-portfolio"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html#load-raw-data",
    "href": "fluanalysis/code/wrangling.html#load-raw-data",
    "title": "Flu Analysis Wrangling",
    "section": "Load Raw Data",
    "text": "Load Raw Data\n\nflu<- readRDS(\"../data/SympAct_Any_Pos.Rda\")"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html#clean-data",
    "href": "fluanalysis/code/wrangling.html#clean-data",
    "title": "Flu Analysis Wrangling",
    "section": "Clean Data",
    "text": "Clean Data\n\n#selecting for variables that don't contain the following character strings of Score, Total, FluA, FluB, Dxname, Activity, or Unique.Visit.\nflurevised <- flu %>% select(-matches(\"Score|Total|FluA|FluB|Dxname|Activity|Unique.visit\"))\n#remove NAs\nflurev <- flurevised %>% drop_na()\n#confirm correct number of variables(32) and observations(730)\nglimpse(flurev)\n\nRows: 730\nColumns: 32\n$ SwollenLymphNodes <fct> Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, No, Yes, Y…\n$ ChestCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ ChillsSweats      <fct> No, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, …\n$ NasalCongestion   <fct> No, Yes, Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, Y…\n$ CoughYN           <fct> Yes, Yes, No, Yes, No, Yes, Yes, Yes, Yes, Yes, No, …\n$ Sneeze            <fct> No, No, Yes, Yes, No, Yes, No, Yes, No, No, No, No, …\n$ Fatigue           <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ SubjectiveFever   <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, Yes…\n$ Headache          <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes…\n$ Weakness          <fct> Mild, Severe, Severe, Severe, Moderate, Moderate, Mi…\n$ WeaknessYN        <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ CoughIntensity    <fct> Severe, Severe, Mild, Moderate, None, Moderate, Seve…\n$ CoughYN2          <fct> Yes, Yes, Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes…\n$ Myalgia           <fct> Mild, Severe, Severe, Severe, Mild, Moderate, Mild, …\n$ MyalgiaYN         <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Ye…\n$ RunnyNose         <fct> No, No, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, No…\n$ AbPain            <fct> No, No, Yes, No, No, No, No, No, No, No, Yes, Yes, N…\n$ ChestPain         <fct> No, No, Yes, No, No, Yes, Yes, No, No, No, No, Yes, …\n$ Diarrhea          <fct> No, No, No, No, No, Yes, No, No, No, No, No, No, No,…\n$ EyePn             <fct> No, No, No, No, Yes, No, No, No, No, No, Yes, No, Ye…\n$ Insomnia          <fct> No, No, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, Y…\n$ ItchyEye          <fct> No, No, No, No, No, No, No, No, No, No, No, No, Yes,…\n$ Nausea            <fct> No, No, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Y…\n$ EarPn             <fct> No, Yes, No, Yes, No, No, No, No, No, No, No, Yes, Y…\n$ Hearing           <fct> No, Yes, No, No, No, No, No, No, No, No, No, No, No,…\n$ Pharyngitis       <fct> Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, No, No, Yes, …\n$ Breathless        <fct> No, No, Yes, No, No, Yes, No, No, No, Yes, No, Yes, …\n$ ToothPn           <fct> No, No, Yes, No, No, No, No, No, Yes, No, No, Yes, N…\n$ Vision            <fct> No, No, No, No, No, No, No, No, No, No, No, No, No, …\n$ Vomit             <fct> No, No, No, No, No, No, Yes, No, No, No, Yes, Yes, N…\n$ Wheeze            <fct> No, No, No, Yes, No, Yes, No, No, No, No, No, Yes, N…\n$ BodyTemp          <dbl> 98.3, 100.4, 100.8, 98.8, 100.5, 98.4, 102.5, 98.4, …"
  },
  {
    "objectID": "fluanalysis/code/wrangling.html#save-cleaned-data",
    "href": "fluanalysis/code/wrangling.html#save-cleaned-data",
    "title": "Flu Analysis Wrangling",
    "section": "Save Cleaned Data",
    "text": "Save Cleaned Data\n\n#save to RDS file\nsaveRDS(flurev, file=\"../data/flurevised.rds\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My website and data analysis portfolio",
    "section": "",
    "text": "Hello\nWelcome to my website and online portfolio!!\n\nPlease use the Menu Bar above to look around.\nIt’s awesome to meet everyone and let’s have a great semester!"
  },
  {
    "objectID": "tidytuesday_exercise.html",
    "href": "tidytuesday_exercise.html",
    "title": "Tidy Tuesday Exercise",
    "section": "",
    "text": "This data is the TidyTuesday data shared for this week of 2023-02-14. It contains information on the age gaps between actors portraying a romantic relationship in 1155 Hollywood movies. The data can be found through the TidyTuesday github repository at https://github.com/rfordatascience/tidytuesday/tree/master/data/2023/2023-02-14.\n\nLoad Packages\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n\n\n\nLoad Data\n\ntuesdata <- tidytuesdayR::tt_load('2023-02-14')\n\n--- Compiling #TidyTuesday Information for 2023-02-14 ----\n\n\n--- There is 1 file available ---\n\n\n--- Starting Download ---\n\n\n\n    Downloading file 1 of 1: `age_gaps.csv`\n\n\n--- Download complete ---\n\nage_gaps <- tuesdata$age_gaps\n\n\n\nExplore Data\n\nstr(age_gaps)\n\nspc_tbl_ [1,155 × 13] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ movie_name        : chr [1:1155] \"Harold and Maude\" \"Venus\" \"The Quiet American\" \"The Big Lebowski\" ...\n $ release_year      : num [1:1155] 1971 2006 2002 1998 2010 ...\n $ director          : chr [1:1155] \"Hal Ashby\" \"Roger Michell\" \"Phillip Noyce\" \"Joel Coen\" ...\n $ age_difference    : num [1:1155] 52 50 49 45 43 42 40 39 38 38 ...\n $ couple_number     : num [1:1155] 1 1 1 1 1 1 1 1 1 1 ...\n $ actor_1_name      : chr [1:1155] \"Ruth Gordon\" \"Peter O'Toole\" \"Michael Caine\" \"David Huddleston\" ...\n $ actor_2_name      : chr [1:1155] \"Bud Cort\" \"Jodie Whittaker\" \"Do Thi Hai Yen\" \"Tara Reid\" ...\n $ character_1_gender: chr [1:1155] \"woman\" \"man\" \"man\" \"man\" ...\n $ character_2_gender: chr [1:1155] \"man\" \"woman\" \"woman\" \"woman\" ...\n $ actor_1_birthdate : Date[1:1155], format: \"1896-10-30\" \"1932-08-02\" ...\n $ actor_2_birthdate : Date[1:1155], format: \"1948-03-29\" \"1982-06-03\" ...\n $ actor_1_age       : num [1:1155] 75 74 69 68 81 59 62 69 57 77 ...\n $ actor_2_age       : num [1:1155] 23 24 20 23 38 17 22 30 19 39 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   movie_name = col_character(),\n  ..   release_year = col_double(),\n  ..   director = col_character(),\n  ..   age_difference = col_double(),\n  ..   couple_number = col_double(),\n  ..   actor_1_name = col_character(),\n  ..   actor_2_name = col_character(),\n  ..   character_1_gender = col_character(),\n  ..   character_2_gender = col_character(),\n  ..   actor_1_birthdate = col_date(format = \"\"),\n  ..   actor_2_birthdate = col_date(format = \"\"),\n  ..   actor_1_age = col_double(),\n  ..   actor_2_age = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\n\nsummary(age_gaps)\n\n  movie_name         release_year    director         age_difference \n Length:1155        Min.   :1935   Length:1155        Min.   : 0.00  \n Class :character   1st Qu.:1997   Class :character   1st Qu.: 4.00  \n Mode  :character   Median :2004   Mode  :character   Median : 8.00  \n                    Mean   :2001                      Mean   :10.42  \n                    3rd Qu.:2012                      3rd Qu.:15.00  \n                    Max.   :2022                      Max.   :52.00  \n couple_number   actor_1_name       actor_2_name       character_1_gender\n Min.   :1.000   Length:1155        Length:1155        Length:1155       \n 1st Qu.:1.000   Class :character   Class :character   Class :character  \n Median :1.000   Mode  :character   Mode  :character   Mode  :character  \n Mean   :1.398                                                           \n 3rd Qu.:2.000                                                           \n Max.   :7.000                                                           \n character_2_gender actor_1_birthdate    actor_2_birthdate     actor_1_age   \n Length:1155        Min.   :1889-04-16   Min.   :1906-10-06   Min.   :18.00  \n Class :character   1st Qu.:1953-05-16   1st Qu.:1965-03-25   1st Qu.:33.00  \n Mode  :character   Median :1964-10-03   Median :1974-07-30   Median :39.00  \n                    Mean   :1960-09-07   Mean   :1971-01-29   Mean   :40.64  \n                    3rd Qu.:1973-08-07   3rd Qu.:1982-04-07   3rd Qu.:47.00  \n                    Max.   :1996-06-01   Max.   :1996-11-11   Max.   :81.00  \n  actor_2_age   \n Min.   :17.00  \n 1st Qu.:25.00  \n Median :29.00  \n Mean   :30.21  \n 3rd Qu.:34.00  \n Max.   :68.00  \n\nglimpse(age_gaps)\n\nRows: 1,155\nColumns: 13\n$ movie_name         <chr> \"Harold and Maude\", \"Venus\", \"The Quiet American\", …\n$ release_year       <dbl> 1971, 2006, 2002, 1998, 2010, 1992, 2009, 1999, 199…\n$ director           <chr> \"Hal Ashby\", \"Roger Michell\", \"Phillip Noyce\", \"Joe…\n$ age_difference     <dbl> 52, 50, 49, 45, 43, 42, 40, 39, 38, 38, 36, 36, 35,…\n$ couple_number      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ actor_1_name       <chr> \"Ruth Gordon\", \"Peter O'Toole\", \"Michael Caine\", \"D…\n$ actor_2_name       <chr> \"Bud Cort\", \"Jodie Whittaker\", \"Do Thi Hai Yen\", \"T…\n$ character_1_gender <chr> \"woman\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", …\n$ character_2_gender <chr> \"man\", \"woman\", \"woman\", \"woman\", \"man\", \"woman\", \"…\n$ actor_1_birthdate  <date> 1896-10-30, 1932-08-02, 1933-03-14, 1930-09-17, 19…\n$ actor_2_birthdate  <date> 1948-03-29, 1982-06-03, 1982-10-01, 1975-11-08, 19…\n$ actor_1_age        <dbl> 75, 74, 69, 68, 81, 59, 62, 69, 57, 77, 59, 56, 65,…\n$ actor_2_age        <dbl> 23, 24, 20, 23, 38, 17, 22, 30, 19, 39, 23, 20, 30,…\n\n\nNext I will check for any missing variables in the dataset.\n\nanyNA(age_gaps)\n\n[1] FALSE\n\n\nThere is no missing data.\nHere I did a basic scatter plot to see the age different by release year.\n\nscatter<- ggplot(age_gaps, aes(x=release_year, y=age_difference, text= paste(movie_name, \"<br>\"))) + geom_point()+\n  labs(title=\"Age Difference by Release Year\")+xlab(\"Release Year\")+ylab(\"Age Difference\")\nscatter\n\n\n\n\nOverall there were more recent movies in the data than older movies, which may partially skew the age gap distributions just from having less data to work from for the pre 1980’s movies. I wanted to try to make the graph interactive with a hover box with the movie title just for practice.\n\nlibrary(plotly)\nggplotly(scatter, tooltip=c(\"text\"))\n\n\n\n\n\n\nI decided to make another graph to see the average age gap each release year to hopefully get more clarity.\n\navg <-age_gaps %>% group_by(release_year) %>% summarize(year_avg = mean(age_difference))\nggplot(avg, aes(x=release_year, y=year_avg))+ geom_line(color=\"dark blue\")+geom_point()+xlab(\"Release Year\")+ylab(\"Average Age Difference\")+labs(title=\"Average Age Difference by Release Year\")\n\n\n\n\nThis graph with the average age differences by year shows that the older movies tended to have a larger age gap on average between the actors, but there doesn’t appear to be a super strong trend.\n\nggplot(age_gaps, aes(x=age_difference))+ geom_bar()+labs(title=\"Frequency of Age Gaps\")+xlab(\"Age Difference in Years\")\n\n\n\n\nFrom this distribution it seems most of the movies had age differences of less than 10 years, with the frequency steadily decreasing the larger the age gap became.\nThe first actor is the older one in the data set, so I decided to look at the age distribution by gender for the older actors and compare it to the younger ones.\n\nbox1<-ggplot(age_gaps, aes(x=character_1_gender, y=actor_1_age))+geom_boxplot(aes(fill=character_1_gender))+\n  xlab(\"Gender\")+ylab(\"Age\")+\n  labs(title=\"Older Actor Age Distribution by Gender\")\nbox1\n\n\n\n\n\nbox2<-ggplot(age_gaps, aes(x=character_2_gender, y=actor_2_age))+geom_boxplot(aes(fill=character_2_gender))+labs(title=\"Younger Actor Age Distribution by Gender\")+xlab(\"Gender\")+ylab(\"Age\")\nbox2\n\n\n\n\nIt seems that for the older actors in the age difference pairs that the men had an older age distribution than the women while it was relatively the same for the younger actors in the pairs. I then want to see if the older actors were typically one gender or the other.\n\nactor1bar<-ggplot(age_gaps, aes(x=character_1_gender))+geom_bar(aes(fill=character_1_gender))+xlab(\"Gender\")+ylab(\"Count\")\nactor1bar\n\n\n\nage_gaps %>% pull(character_1_gender) %>% table()\n\n.\n  man woman \n  941   214 \n\n\nThe bar graph showed that the large majority of the older actors were men so I checked the actual numbers and found out that 941 were men and 214 were women.\n\nactor2bar<-ggplot(age_gaps, aes(x=character_2_gender))+geom_bar(aes(fill=character_2_gender))+xlab(\"Gender\")+ylab(\"Count\")\nactor2bar\n\n\n\nage_gaps %>% pull(character_2_gender) %>% table()\n\n.\n  man woman \n  215   940 \n\n\nThe frequency is reversed for the younger actors with the majority of them being women with 940 women and 215 men. This the made me wonder how many non-heterosexual pairings there were.\n\nmm<- age_gaps %>% filter(character_1_gender==\"man\") %>% filter(character_2_gender==\"man\") %>% count()\nff<- age_gaps %>% filter(character_1_gender==\"woman\") %>% filter(character_2_gender==\"woman\") %>% count()\nmm\n\n# A tibble: 1 × 1\n      n\n  <int>\n1    12\n\nff\n\n# A tibble: 1 × 1\n      n\n  <int>\n1    11\n\n\nThere appears to be 12 movies with both actors being male and 11 with both actors being female.\nI’m now kind of curious about which movie had the largest age gap and also which had the smallest.\n\nage_gaps %>% pull(age_difference) %>% range()\n\n[1]  0 52\n\nage_gaps %>% filter(age_difference==52)\n\n# A tibble: 1 × 13\n  movie_name     relea…¹ direc…² age_d…³ coupl…⁴ actor…⁵ actor…⁶ chara…⁷ chara…⁸\n  <chr>            <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n1 Harold and Ma…    1971 Hal As…      52       1 Ruth G… Bud Co… woman   man    \n# … with 4 more variables: actor_1_birthdate <date>, actor_2_birthdate <date>,\n#   actor_1_age <dbl>, actor_2_age <dbl>, and abbreviated variable names\n#   ¹​release_year, ²​director, ³​age_difference, ⁴​couple_number, ⁵​actor_1_name,\n#   ⁶​actor_2_name, ⁷​character_1_gender, ⁸​character_2_gender\n\nage_gaps %>% filter(age_difference==0)\n\n# A tibble: 30 × 13\n   movie_name    relea…¹ direc…² age_d…³ coupl…⁴ actor…⁵ actor…⁶ chara…⁷ chara…⁸\n   <chr>           <dbl> <chr>     <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>  \n 1 10 Things I …    1999 Gil Ju…       0       2 Joseph… Larisa… man     woman  \n 2 A Happening …    2017 Judy G…       0       2 Common  Jennif… man     woman  \n 3 A Simple Fav…    2018 Paul F…       0       2 Henry … Blake … man     woman  \n 4 American Hus…    2013 David …       0       3 Christ… Amy Ad… man     woman  \n 5 American Pie     1999 Paul W…       0       4 Mena S… Chris … woman   man    \n 6 Blue Valenti…    2010 Derek …       0       1 Michel… Ryan G… woman   man    \n 7 Catch Me If …    2002 Steven…       0       1 Amy Ad… Leonar… woman   man    \n 8 Chicago          2002 Rob Ma…       0       2 Renee … Domini… woman   man    \n 9 Daddy's Litt…    2007 Tyler …       0       1 Idris … Gabrie… man     woman  \n10 Empire           2002 Franc.…       0       2 Denise… Peter … woman   man    \n# … with 20 more rows, 4 more variables: actor_1_birthdate <date>,\n#   actor_2_birthdate <date>, actor_1_age <dbl>, actor_2_age <dbl>, and\n#   abbreviated variable names ¹​release_year, ²​director, ³​age_difference,\n#   ⁴​couple_number, ⁵​actor_1_name, ⁶​actor_2_name, ⁷​character_1_gender,\n#   ⁸​character_2_gender\n\n\nThe movie with the age difference of 52 was Harold and Maude released in 1971. However there were 30 movies where the age difference was not even an entire year."
  },
  {
    "objectID": "tidytuesday_exercise2.html",
    "href": "tidytuesday_exercise2.html",
    "title": "Tidy Tuesday Exercise 2",
    "section": "",
    "text": "To be filled"
  },
  {
    "objectID": "visualization_exercise.html",
    "href": "visualization_exercise.html",
    "title": "Visualization Exercise",
    "section": "",
    "text": "The graph I settled on to replicate plots different colleges’ fight songs by duration in seconds and beats per minute. I found this graph on fivethiryeight.com at this link https://projects.fivethirtyeight.com/college-fight-song-lyrics/ and the raw data at this link https://github.com/fivethirtyeight/data/tree/master/fight-songs. Here is a quick screenshot of the original graph since it is slightly interactive, but if you would like to view it in its full glory then check out the link above. \nLoad packages\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0      ✔ purrr   1.0.1 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.5.0 \n✔ readr   2.1.3      ✔ forcats 0.5.2 \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(readr)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(shiny)\n\nLoad in data\n\nfight <- read_csv(\"data/fight-songs.csv\")\n\nRows: 65 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (19): school, conference, song_name, writers, year, student_writer, offi...\ndbl  (4): bpm, sec_duration, number_fights, trope_count\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nPlotting\n\n##create the plot with parameters and average lines\nPlot1 <- ggplot(fight, aes(x=sec_duration, y=bpm, col=school, text= paste(school, \"<br>\")))+\n  geom_point(size=3, alpha=0.8)+\n  xlab(\"Duration\")+ylab(\"Beats Per Minute\")+\n  geom_hline(yintercept = mean(fight$bpm, na.rm=TRUE), lty='dotted')+\n  geom_vline(xintercept= mean(fight$sec_duration, na.rm=TRUE), lty='dotted')+\n  scale_colour_hue(c=20, l=80)+theme(legend.position=\"none\")+\n  scale_x_continuous(limits= c(0,180), breaks = seq(0,180,20))+\n  scale_y_continuous(limits= c(50,200), breaks= c(0,60,80,100,120,140,160,180,200))+\n  theme(axis.title.y = element_text(face=\"bold\", size=11), plot.title = element_text(face=\"bold\", size=14.5, hjust=0.5), axis.title.x = element_text(face=\"bold\", size=11))+\n  ggtitle(\"How Colleges' Fight Songs Stack Up\")+\n  annotate(\"text\", x = 140, y = 190, label = \"Fast but long\")+\n  annotate(\"text\", x = 30, y = 190, label = \"Fast and short\")+\n  annotate(\"text\", x = 30, y = 50, label = \"Slow but short\")+\n  annotate(\"text\", x = 140, y = 50, label = \"Slow and Long\")+\n   theme(panel.background = element_rect(fill = 'white'),\n          panel.grid.major = element_line(color = 'grey'),\n          panel.grid.minor = element_line(color = 'grey'))+\n  annotate(\"text\", x=140, y=130, label=\"AVERAGE\", size=3)+\n  annotate(\"text\", x=71, y=100, label=\"AVERAGE\", angle=90, size=3)\nPlot1\n\n\n\n\nI started with plotting the basic parameters and then started tweaking things to make them more similar to the original. I started with the point size and transparency, then added axis labels and the average lines for bpm and duration. I altered the scale of both axes, added the title, changed the font, and added quadrant labels as well. Lastly I changed the background grid to how the original looked. As I was going along, I would view the graph and see how it was looking, then add to the code. I can see how this may be harder to follow than if I broke it down into separate steps.\nAdding the Hovering Text Box\n\n##create the hover text box\nggplotly(Plot1, tooltip = c(\"text\"))\n\n\n\n\n\nComments\nStackoverflow was my best friend during this process and I would’ve been lost without it. I came into this exercise with a basic understanding of making plots but I didn’t know all the ways to customize the different aspects of a graph or any sort of interactive elements, and it was my first time trying to use ggplotly. I definitely learned a ton of details for personalization and formatting which took the majority of the time I spent on it. I had a difficult time figuring out what color palette was used in the original so I settled for the default colors which were fairly similar. I also couldn’t figure out how to add the labels of ‘AVERAGE’ within the dotted average lines I made, so I just added them adjacent to the lines. This was defintely a challenge but I feel like I learned a lot and found a bunch of new resources I can turn to in the future."
  }
]